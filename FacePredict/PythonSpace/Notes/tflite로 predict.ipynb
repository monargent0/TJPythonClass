{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # keras 아님 , C언어 같음\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFLite model을 읽어와서 tensor에 할당하기\n",
    "interperter = tf.lite.Interpreter(model_path=\"../Data/CNN/best-gray-cnn-model.tflite\")\n",
    "interperter.allocate_tensors() # 대충 배열 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model의 입력과 출력을 정하기\n",
    "input_details = interperter.get_input_details()\n",
    "output_details = interperter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      "[{'name': 'serving_default_conv2d_input:0', 'index': 0, 'shape': array([  1, 400, 300,   1], dtype=int32), 'shape_signature': array([ -1, 400, 300,   1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "\n",
      "Output details:\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 17, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# model의 input과 output의 구성 출력해보기\n",
    "print(\"Input details:\")\n",
    "print(input_details)\n",
    "print()\n",
    "print(\"Output details:\")\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측할 이미지 불러와서 numpy 배열로 변경하기\n",
    "path = \"../Data/FaceGray/Cathy/image_0000.jpg\"\n",
    "load_img = np.array(Image.open(path).resize((400,300)))\n",
    "input_data = np.array([load_img], dtype = np.float32)\n",
    "input_data = input_data / 255 # 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'serving_default_conv2d_input:0',\n",
       " 'index': 0,\n",
       " 'shape': array([  1, 400, 300,   1], dtype=int32),\n",
       " 'shape_signature': array([ -1, 400, 300,   1], dtype=int32),\n",
       " 'dtype': numpy.float32,\n",
       " 'quantization': (0.0, 0),\n",
       " 'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "  'zero_points': array([], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_detail의 [0]번 값만 출력해보기 <- input_Data의 reshape시 필요\n",
    "input_details[0] \n",
    "# shape 확인\n",
    "# 이번에 바뀐 내용@ 인터넷 검색해도 안나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 'quantization': (0.0, 0), \n",
    "-> 예측력 조절하는 부분. tflite 는 실행할때마다 예측력이 달라진다...?\n",
    "예측력 조절까지 가능하면 미국 진출 가능 ㄷㄷ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data를 input_details에 넣기\n",
    "interperter.set_tensor(input_details[0]['index'], input_data.reshape(1,400,300,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측하기\n",
    "interperter.invoke() # 얘를 실행을 해야 예측하는 것이다@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0428154e-07 2.1834632e-07 9.9999952e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 예측한 결과 보기\n",
    "output_data = interperter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cathy\n"
     ]
    }
   ],
   "source": [
    "dirNames = ['Aiden' ,'Andrew', 'Cathy']\n",
    "print(dirNames[np.argmax(output_data[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h5의 핵심만 가져와서 가볍게 사용하는게 TFlite라고 이해하면 된다.              \n",
    "h5의 학습데이터는 안가져오고 식만 가져오는 정도. 그래서 TFlite는 모든 데이터가 초면이다.                 \n",
    "학습데이터가 없기때문에 같은 사진을 두번 넣어도 두번다 초면으로 취급한다.                \n",
    "tflite의 예측률이 낮을 경우 h5의 예측률을 높여서 다시 만들어 본다.               \n",
    "                       \n",
    "지금 같은 경우도 h5를 만든 학습 데이터의 양이 적기 때문에 h5에서 데이터는 잘 맞춰도 tflite에서의 예측률은 훨씬 떨어질 수 있는 것이다.                  \n",
    "--> 그래서 사진 한 장당 -15도 +15도 30개씩으로 늘려서 데이터 양을 18*30 * 3으로 만들어 보면 좋을 듯             \n",
    "--> + 좌우 반전으로 * 2 로 늘리는 것도 가능 . 예측력 높여서 포트폴리오로 쓰는 것도 가능하다             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c34e8390e776d2ee205b71ed5a6130fee3cef8da5e87e926ce18e14f4a070d72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
